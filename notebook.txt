Sunday 29th October

I've decided not to implement a complete solution for timestamps. For now, I'll keep the flat structure of phrases
and timestamp events and most consequences with current time. The exception is knowledge, which will get the timestamp
of the earliest phrase in the phrase list.

In practice, whenever we add consequences, whether for events or static knowledge, we give the timestamp of the record, the current
record.

As of now, there is no inferring from the knowledge base of a specific person. So even if John knows that Daryl went to Fiji,
he does not directly infer that Daryl is in Fiji. Instead we use inference from the static db (objective knowledge) to do that

Probably would make more sense to have a centralized step creation mechanism that includes events, inter-person questions, responses etc.
Attach a gens-type, such as stroy-step, knowledge insertion, etc.

Tuesday 31st October

Pushed the commit 'Answering personal questions'

An answer is generated but the next step is to add the contents of the answer as knowledge

Wednesday 1st November

Finished adding the answer to an inter-person query into the story database.

Will commit a version with above string

I intend to remove the generation of phrases for rules just for the purpose of learning because (1) that is about to change
and (2) some rules such as the knowledge resulting from telling rule generated millions of records.

A thought about time:
4 kinds of phrases:
state (as in John wants the wheel - that is always true)
current (as in Mike has the purse - this automatically updates its time. If it was true last stem, unless removed,
        it is true the next step. Note true for objective facts but not knowledge)
event (Harry went to the UK. Always has a specific time)
phase (Terry knows that Mile has the purse - this is true for a time. It can go out of date unless specifically updated)

Further note. Currently knows that has a time stamp of the object of the knowledge. We may need to break down a phrase into
constinuent pieces wach with their own time.


It doesn't make sense to have so many functions, each creating rules. There should only be one function for rule but many
differnt types that use something like the mostly defunct 'story_based, b_db, b_story'. Each step in the story advnacing process
must pick out the kind of rules it needs and advance them.

Next, I will add motivations. The current idea is:
(1) A steady state of wanting
(2) If you want x and you know that x is located in y you go to y
(3) If you want x and you are located with x and x is free pick up x
If you want x and you are located with x and z has x ask z for x

Thursday 2nd Nov

Rearrangin rules. Removed defunct b_db and b_story that weren't being used anyway. Added rule_type that falls into a number of categories:
story_start - used to initialize where people and objects are and what objects people want
event_from_none - used to create a story step (event) based on other states (rather that events responding to events)
state_from_state - update states based on other states. For example if Jon is in UK and glass is in UK then Jon knows glass is in UK
state_from_event - update states as a result of an event. Jon has the purse and Jon went to France, so create a story phrase that the purse is in France (remove old)
event_from_event - used to create a story step (event) based on another event (John gives if John is asked)
block_event - used to block events. So a rule that says that Jon gave to Jon is blocked
knowledge_query  - used in response to queries to first create a personal db of the knowledge of a particular person
query - used to test any knowledge base

used the opportunity to make rule indentations consistent

we need to replace var_id numbers by symbolic constants. A next step could be to translate this to he current form. It's
    just very difficult to write rles without bugs using the current form

While I'm at it, do the same for referring to clauses within the AND. It will be useful for time stamps

Added a probability for event_from_none rules so that we can prioiritize debugging or events that are caused by wants

Added a probability for state_from_event so that some rules don't automatically run after an event (e.g. like)

The are only two like states: likes and nothing.
Giving something to somebody that they want is definately gonna cause a like
Telling somebody something, which can only come after a question might get a like

Committing with the label:
Added likes and instory queries

Monday 6th Nov

Committed version with the message:

"Preparing for learn. Added controlled garadual learning. curriculum. and generating possible rules to genrate results."

Added curriculum.py. Similar to story.py but gets specific rules by names. At first is just adds a simple pickup rule and
gets the 'has' consequence phrase.

This is then passed with the story and the event to cascade.py which finds all phrases that includes the input words and
then cascades on all the words it finds

Back in curruculum.py, take all the permutations of the cascaded phrases and for each perm creates a rule with no vars.
Next, grenerate a rule replacing all repeated occurences of words with vars and looking like a rule.

Now I will work to incorporate standard GloVe or Word2Vec vectors for all words so that we can create an embedding for the rule.

Wednesday 8th Nov

About to commit a version with the message:

Added parse.py and embed.py together to create .glv files for embedding.

Added two stand-alones. parse.py calls StanfordNLP to create a dep tree of each of the objects and actions.
It creates a .nlp file where each row contains
1. The original text
2. The number of words
3. For each word:
    The dep relation for which that word is the dependent
    The idx (1-based) of its governing word
    The word itself

embed.py creates a .glv for each of actions, names, objects and countries. Countries and names are simply looked up in
a GloVe database and the 50 values appended as an embedding. Objects and Names parse the .nlp and add the following
embed vectors:
1. the word itself - the vec from GloVe
2. The dep relation - a one hot binary float vec
3. The governing idx a one hot up to the max idx

If phrases are longer than 4 words they are rejected. If they are less they are padded with an <invalid> dep rel, zeros and
max index + 1.

fixed bug in els.py: make_vec. If there was only one record, the code output a shape of dim 1 instead of 2

Sunday 12th November

Start of day todo:

Move the initialization of elements into cuuriculum.py

Apply state to story and move the story along to enrich the types of rules we are trying to learn

Batch inputs of rules according to length of input

Put headers on the vec representation of phrases or rules. These headers recurse into the body

A header consists of a number and that number of offsets
    Any number can be represented as a 0-1 float by appliying a factor of ten multiplier. To make up to 1000, div by 10000
    Three els in a phrase (john, picked up, the ball) are represented as 3, 0, 125, 325 if that is where each el starts
    An el itself can be composed of deps, so an el begins with a header with the number of deps and their offsets
    A dep consists of the word, its dep rel and the index of the governor. So a dep, too begins with num (3) and offset

Monday 13th November

Yesterday I completed batching of inputs. For now I assume that in curriculum.py processes rules that come from cascade and
only have the sel_el field set and no groups. Therefore each rule can only generate one rec. Once the rules are batched by input
length, there needs to be an indexing into the original rule list or a rearrangement of that list.

After much thinking I think the best plan is as follows:

1. Learn a transformation of the rule vec into a short fixed-length key vector *key1*
    a. This transformation can consist of multiple nets, one for each length
    b. A net could be as simple as a matmul
2. Cascade to find all phrases related to an input event plus the event itself
3. Create all orderings of each component of the cascade (query options)
    a. Apply var_dict processing to each query option to make later matching easier
4. Transform the vec of all the query options to a key of the same length as 1.
5. Match each query option (not the vec) to each of the rules in the db. Generate the gens from the preconds *key2*
    a. The instantiation of the vars in the gens is from the values in the query option
    b. Padding is required so that all vars can get something - even if it is only an empty string
    c. Another option is to immediately decide that this query option fails to match on this rule
6. Compare the gens of the match in the last step to the training result of the event
    a. [TBD] what if there are more than one result
    b. If the (instantiated) gens matches, we want key1 and key2 to be close to each other (cosine distance close) to 1
        else, far apart

Committing before starting to implement this with the message:
Implemented batching of rules by vec length

Potential inefficiency. In init_train_tensors, each vec for each rule will be multiplied separately
OK. Couln't stand the inefficiency and fixed it.

Moved do learn into a helper function called create_train_vecs. Now do_learn() can call the latter twice, once for
a database and once for queries. The only real difference is that queries expand out to all permutations of each combination.

I don't know whether we should query compare the recs or the rule. First shot the recs.

Sunday 19th November

Checking in a version with the following comment:

Training and Evaluation working on very simple rules

The training consists of creating rules-like description of succesful instances. Creating a db of all combinations as described above
Embedding these using a set of matrices all to the standard key length
Doing this again for queries and using embedding matrices to get to the same key length
Creating a success matrix for xomparison of each query rule with a db rule. Success means that any object substitution
    still yields the expected result of the query
Learning the embedding such that the hits in the success matrix put the db items with their queries

The evaluation consists of another set of queries
This time all queries that end up with an embedding vector length are discarded
Compare each eval-query to all rules in the db. Cosine Distance is used for now
Find the closest 5 rules to the query in embedded space
Create a score based on how many of these 5 are hits divide by min(k, total-hits)

Next the goal is to search for a symbolic representation of the rules
Proposal is as follows:
1. Do a k-means on the db in embedded space.
2. For each cluster, find rules (actually recs) of the same length (number of phrases)
3. Evaluate the distance within the cluster of the different members at each phrase
4. Define a groupimg for each such phrase-distance group
5. Look for the same grouping in other places.
6. Create versions of the rule that can utilize these groupings.

Monday 20th November

We're pretending we are creating the y_db in batches.Right now there is only one batch
and the y_db is passed in from the outside.

Tuesday 21st November

Created a function out of the code for match_phrases that just matches the preconds. This is needed for the build_sym_rules()
so that we can create clusters out of the embedded db recs where in fact all the members of the clusters are compatible.

Actually, to explain a little, what I did was to first take the embedded version of all the db recs and do a kmeans on
them to get clusters. However, I want all members of a cluster to be compatible, so I split the clusters themselves
into a lower-level cluster where each low-level cluster is compatible with all other members. Compatible means the
same number of els in the rec and the all vars match by id and all objs match all objs

Wednesday 22nd November

Checking in a version with the following comment:

Added kmeans clustering of embedded recs of the db

Thursday 23rd November

Checking in a version with the following comment:

Changed embed module to combine all vecs of el phrase to one vec

Sat 25th November

How do we represent a rule that was built from instances in a cluser

The first idea is to add two fields to rec_def_type

Monday 27th November

Checking in with comment:

Created first pass of sym rules, creating sets and some combination.

Wednesday 29th November

for now everything is in do_learn. Ignore all the rest

Checking in with comment:

Creating first pass learned rules. Some evaluation but not excluding unnecessary clauses.

Thursday 30th November

Moved the glv_dict creation outside the curriculum learning but all other set creation and rule initiation happens inside
each iteration of story creation, whether for the database, queries or evaluation set

Wednesday 6th December

Checking in with comment:

Learned rules succeeds for simplest stories

Checking in with comment:

Added a criteria of most specific rule wins

Wednesday 13th December


Conversation opened. 1 read message.


Skip to content
rec text
Inbox
x

Eli Ehrman <ehrman.eli@gmail.com>
Attachments4:37 PM (21 minutes ago)

to me
Attachments area

Click here to Reply or Forward
13.37 GB (89%) of 15 GB used
Manage
Terms - Privacy
Last account activity: 4 minutes ago
Details


csc_list
sort by len  = total number of words in a all phrases
for each csc comb, find all permutations
	select all equally high-scored perms (var positions etc)
	create rec with vars
	calc rec len and svo pattern
		There is a svo for the preconds and a svo plus o list for the gens
		svo rules
			c for conn
			followed by s, e, a and r (r for or)
			v for var
			followed by two digit var num 0 padded
			o for obj (will translate to anyobj, obj and set)
			g placed between preconds and gens only for lexical ordering
				correction ordering must be based on preconds alone
	for each rec
		Find its len grp, templ,
		Is there ust one gg or many?
		if one:
			do i match gg?
			if not, create new gg
		if > 1 gg, whether from before or now
			does new input match on one of the gg's mrg?
			does it fail to mmap on competing gg's mrg's
			if both yes, add to the statistic and cosider upgrading mrg confidence
			if not,
				attempt to broaden
				look at other rec of the mrg as well as recs from other gg's
				if competing gg's now fit ito broadened category
					backtrack on broadening and trycreating a new mrg
					do the same checks
				if you cant't make this work - shout for help
					might need a NN solution here
				if there is a longer rule that has none of these problems, give him the confidence
				might need to take recs out of the mothballs
		dig down to mrg
		if complete confidence reached
			remove all event insertions
			stop
		if confidence relative to longer
			keep going as long as incming recs are no longer
		if fail where no prev failure on high confidence
			TBD
		if match grp found, and success
			add to eid success group
			add mrgid to event list successes
		if mrg match but fail
			search

list of len groups, sorted by len
c_len_grp
	len
	template list (sorted by var score?)
c_templ_grp
	var score?
	svo pattern
	event_id_set success
	eid fail
	gens grp list
		if only one, template is enough
c_gens_grp
	svo pattern and olist (only obj allowed, not anyobj or set)
	match rec group (mrg) list
		at least one, the top level with all o fields set to anyobj ????
		at least one, defining how to distinguish recs that match the parent template from other cgg's
c_mrg
	o-list. list of all obj fields.
		anyobj, obj and set.
	eid success list
	eid fail
	child mrgs
		defined as same o-list but one field more restricted, otherwise a sibling not a child
rec_match_group.txt
Open with
Displaying rec_match_group.txt.

Thursday 14th December

More details on the same:

c_gg test
	list of c_mrgs
	for each mrg
		if !match
			irrelevent
		if match and !correct
			problem for the whole gg and maybe template
		if match and correct
			match_found
	if !match_found
		for each mrg
			add to perm_list
			create new rule
				for each gg in templ
					if not curr gg
						continue
					for each perm_rec in gg
						if match perm_rec to new rule
							fail on new rule

		create new mrg
			???repeat test for all other gg's


for each new perm
	for each templ match
		for each gg
			if correct (test with gg is all that's needed)
				for each mrg
					look for at least one match
				if founf add to scoring for that mrg
				if !found do above proc
			if !correct
				for each mrg,
					check that no match
					but if match add to fail scoring

Sunday,  17th December

Giving up on the direction of mrg.

Checking in just to keep some record of the code with the message:

Version not working. Giving up on mrg

I think i'm going to take a different tack
Yes to len grps and templ groups
yes there are a number of different gens for each templ group
no to gens groups and mrg's
use nn, distance metric learning and cosine distance
c_templ_grp
	o-len
	gens_arr (with dict?)
	list of perm_rec with gens_arr_idx
	tf call tree
	nn_transform
	db of transformed perm_rec with gens_arr_idx
	(loss function uses distance between gens's?)

new perm_rec
	if num prev perm > 2 and num gg's  > 1
		if nn/transform is none
	        create new instance of nn/transform
	do transform
	do knn on all recs so far
	generate result
		use two stage:
			build var dict from preconds
			fill in results for each match
				perhaps cache results of gens that was already calculated
	create score
		score a fn of:
			number of results if less than k
			% correct
				n number correct / k. (even if there are not k results)
			average cd
				n * cd / k
		if score passes thresh
			add eid to success list for gens
    else
do a few rounds of learning
	get matching gens
		if no match: extend gens_arr

Once confidence is reached, go to other templates with the same eids and delete the perm recs
	Can do this

Saturday 23rd December

Sent myself the following:

for all ggs that have graduated

for any event, not event result , see if it is activated

create a special nn:
    lots of spare nodes of input
    every graduated gg is an input and output

Actually gonna change tack again (within the last tack, sort of)

I want to join the event results for each event step (story step). So a record in the db is associated
with the event step. Then each record might have a number of different gens or event results associated
with it. After all, the cascade is on the event step and not the results so it is the same for
all results of that step.

Before proceeding, I check in what I wrote so far. It actually works well except that it does not achieve
the desired result. The nn learns as well as it can the gens. The problem is that if all the inputs are
identical, it cannot learn to really distinguish the same input doing this or that.

I will check in with the comment:

Learning each gg for each preconds rec separately, but learning only on ggs substantiated with many eids

One last comment on the change just made is the concept of a graduated gg. A graduated gg is a gg that
has a threshold number of eids. The idea is that a gens with a non-variable which is diferent for each
eid is not something worth loearning. To deeal with this I introduced the provisional gg (pgg)

In the new porposed scheme you find close examples of preconds recs but each one can have multiple events it generated.

Sunday 24th December

Todo:
    Write a new get_score function so that it scores an indvidual graduated gg (startt with get_match_score)
    Write a summary of the successes for an event to decide whether to promote graduated to successful

match score:

for each event
	for each perm
		find template
		if first-pass and template has confirmed or second-pass and template has graduated
			find closest perms in template db
			for each gg
				if closest matches support this gg:
					gen result
					if result list not known (inference stage only)
						if gg confirmed
							output result!!!!!!!
					else if result in result list:
						for that result_list entry add the len, template and score
						if gg confirmed:
							mark result as match-confirm
							if all results have match-confirm
								continue to next event!!!!!!
					else result not in result list and list exhaustive
						mark gg as bad


	for each result:
		find best gg among results
			best score and if tied, shortest len
			give a point to the gg

	if a gg crosses a point thresh
		add to confirmed list

Monday 25th December

Yet again I will change tack.

The NN will need to be on a per gg basis (not pgg) rather than on a per-template basis. The result will be yes/no
on the specific gg.

First I will check in current code with the following comment:

Code running but unsatisfactory results. Check in beore change to per-gg NN

Friday 29th December

Implemented:

learn

for each graduated gg, learn a NN for all the per list with outcome 1/0 were 1 means that one of the results
belongs to the gg

each gg has an arr 1-to-1 correspondence with templ per_list. 1 means has a matching result. learn closeness

score

for each gg
	if the closest matches indicate 1
		gen output
		if learning and matches one of the outputs
			add a record to score_result_list for that result
				members of the gg create a minimum cd for acceptance
			if confirmed gg
				mark result confirmed

So NN is per gg. Once all the results are confirmed, the processing for that event step stops.
There is some scoring based on event results not happening

I found that without this scoring, one rule was getting confirmed despite providing unecessary data. However,
its own cds were creating a threshold of 0.2+. Rather than use that fact, I added a scoring mechanism so that
it should be overridden by a correct rule, even if longer.

Checking in with message:

Sort of working. NN is gg based. Score based on successes after match. Stop when all results has been matched by confirmed rules.